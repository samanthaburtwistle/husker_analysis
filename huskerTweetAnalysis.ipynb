{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Huskers vs. Buckeyes Game via Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a nice, cleaned data set of Tweets from the Nebraska vs Ohio State game on September 28th, let's do some basic data analysis and separate the Tweets into state-based data sets!\n",
    "\n",
    "*note*: this is a work in progress and may be updated later, with projects like making n-grams out of common words and using tf-idf in order to determine which words are most correlated with Nebraska vs. Ohio state of origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Username', 'Tweet ID', 'Time', 'User Location', 'Text',\n",
      "       'Tweet Geo Coordinates', 'Is Retweet', 'Is Quote Tweet', 'Sentiment'],\n",
      "      dtype='object')\n",
      "(13190, 10)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "import itertools\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#load the data set\n",
    "tweets = pd.read_csv(\"Documents/Husker Project/cleanedGameTweets.csv\")\n",
    "\n",
    "#and get some basic info about it\n",
    "print(tweets.columns)\n",
    "print(tweets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One small thing: I neglected to get rid of \"stop words\" (common words that don't add much to the text analysis, like \"an,\" \"the,\" \"that,\" etc). Using the nltk list of common English stop words, I'm going to remove them from my Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               ['ohio', 'state', 'over', 'team', 'total']\n",
      "1                 ['go', 'big', 'red', '#huskers', '#gbr']\n",
      "2        ['brock', 'osweiler', 'at', 'today', 's', '#hu...\n",
      "3        ['shewrap', 'ohio', 'state', 'when', 'they', '...\n",
      "4                           ['let', 's', 'go', 'buckeyes']\n",
      "5        ['i', 'think', 'tonight', 'is', 'the', 'night'...\n",
      "6        ['hours', 'later', 'off', 'hours', 'of', 'slee...\n",
      "7                                        ['old', 'friend']\n",
      "8        ['clemson', 'survives', 'unc', 'but', 'what', ...\n",
      "9        ['no', 'ohio', 'state', 'marching', 'to', 'vic...\n",
      "10                              ['love', 'my', 'buckeyes']\n",
      "11       ['lets', 'go', 'bucks', '#gobucks', '#buckeyen...\n",
      "12       ['do', 'you', 'really', 'think', 'that', 'as',...\n",
      "13       ['go', 'jeremy', 'ruckert', 'and', 'ohio', 'st...\n",
      "14       ['it', 'was', 'tough', 'especially', 'with', '...\n",
      "15       ['i', 'hope', 'nebraska', 'wins', 'in', 'my', ...\n",
      "16       ['old', 'dominion', 'played', 'horrible', 'st'...\n",
      "17       ['espncfb', 'hdouglas', 'treavorscales', 'i', ...\n",
      "18       ['neighbors', 'have', 'been', 'warned', 'dinne...\n",
      "19       ['at', 'home', 'with', 'my', 'wife', 'my', 'do...\n",
      "20       ['there', 's', 'the', 'little', 'cutie', '#buc...\n",
      "21       ['i', 'am', 'hilarious', 'fuck', 'what', 'anyo...\n",
      "22       ['i', 'will', 'fight', 'anyone', 'that', 'says...\n",
      "23                                      ['go', 'buckeyes']\n",
      "24       ['wet', 'field', 'wet', 'football', 'better', ...\n",
      "25       ['f', 'fly', 'over', 'not', 'too', 'shabby', '...\n",
      "26       ['drying', 'out', 'in', 'lincoln', 'just', 'in...\n",
      "27                                    ['it', 'is', 'time']\n",
      "28       ['i', 'hope', 'nebraska', 'and', 'ohio', 'stat...\n",
      "29       ['final', 'thoughts', 'osu', 'nebraska', '#hus...\n",
      "                               ...                        \n",
      "13160    ['yosoy', 'kemp', 'bama', 'lsu', 'clemson', 'g...\n",
      "13161    ['huskers', 'hey', '#huskers', 'what', 'happen...\n",
      "13162    ['just', 'like', 'michigan', 'look', 'forward'...\n",
      "13163    ['laurarutledge', 'ohiostatefb', 'auburnfootba...\n",
      "13164    ['gahhdamn', 'did', 'these', 'niggas', 'even',...\n",
      "13165        ['celebration', 'in', 'lincoln', '#buckeyes']\n",
      "13166    ['didn', 't', 'y', 'all', 'just', 'say', 'the'...\n",
      "13167    ['jaxfryburger', 'kirbyownsmullen', 'it', 's',...\n",
      "13168    ['i', 'put', 'this', 'lose', 'solely', 'on', '...\n",
      "13169    ['retweeting', 'this', 'in', 'honor', 'of', 'w...\n",
      "13170    ['highlights', 'ohio', 'state', 'blasts', 'neb...\n",
      "13171    ['mattrudolph', 'hey', '#huskers', 'what', 'ha...\n",
      "13172                         ['shots', 'fired', 'beasts']\n",
      "13173    ['buckeye', 'haters', 'can', 'eat', 'that', 'c...\n",
      "13174     ['felt', 'like', 'it', 'should', 'have', 'been']\n",
      "13175    ['colton', 'glad', 'your', 'enjoying', 'your',...\n",
      "13176    ['forever', 'red', 'but', 'that', 'was', 'a', ...\n",
      "13177    ['just', 'tw', 'nutz', 'hangin', 'out', 'congr...\n",
      "13178    ['sean', 'callahan', 'husker', 'did', 'you', '...\n",
      "13179    ['harmosa', 'kirkherbstreit', 'ohiostatefb', '...\n",
      "13180    ['don', 't', 'me', 'but', 'nobody', 'wins', 'w...\n",
      "13181    ['isn', 't', 'it', 'like', 'week', 'idk', 'who...\n",
      "13182         ['ohio', 'state', 'beats', 'the', 'huskers']\n",
      "13183                      ['i', 'm', 'happy', '#gobucks']\n",
      "13184          ['absolutely', 'rebuilding', 'year', 'gbr']\n",
      "13185    ['third', 'time', 'the', 'color', 'commentator...\n",
      "13186    ['will', '#ohiostate', 'be', 'in', 'the', '#co...\n",
      "13187    ['how', 'about', 'that', '#husker', 'volleybal...\n",
      "13188                              ['beat', 'that', 'ass']\n",
      "13189    ['i', 'still', 'hate', 'ohio', 'state', 'and',...\n",
      "Name: Text, Length: 13190, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# what the tweets look like now\n",
    "type(tweets['Text'])\n",
    "print(tweets['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# seeing what the pre-loaded stopwords look like\n",
    "stopWords = stopwords.words('english')\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               [ohio, state, team, total]\n",
      "1                           [go, big, red, #huskers, #gbr]\n",
      "2                 [brock, osweiler, today, #huskers, game]\n",
      "3        [shewrap, ohio, state, win, aldi, kroger, bowl...\n",
      "4                                      [let, go, buckeyes]\n",
      "5        [think, tonight, night, adrian, martinez, thro...\n",
      "6        [hours, later, hours, sleep, stop, us, cheerin...\n",
      "7                                            [old, friend]\n",
      "8        [clemson, survives, unc, game, notre, dame, dr...\n",
      "9        [ohio, state, marching, victory, go, buckeyes,...\n",
      "10                                        [love, buckeyes]\n",
      "11       [lets, go, bucks, #gobucks, #buckeyenation, #t...\n",
      "12       [really, think, husker, fan, unaware, game, go...\n",
      "13       [go, jeremy, ruckert, ohio, state, beat, nebra...\n",
      "14       [tough, especially, ending, clemson, game, sav...\n",
      "15       [hope, nebraska, wins, head, delusional, enoug...\n",
      "16       [old, dominion, played, horrible, st, half, oh...\n",
      "17       [espncfb, hdouglas, treavorscales, picking, oh...\n",
      "18       [neighbors, warned, dinner, crockpot, osu, fla...\n",
      "19       [home, wife, dog, homemade, lasagna, nebraska,...\n",
      "20       [little, cutie, #buckeyenation, baby, buckeye,...\n",
      "21                          [hilarious, fuck, anyone, say]\n",
      "22          [fight, anyone, says, ohio, midwestern, state]\n",
      "23                                          [go, buckeyes]\n",
      "24       [wet, field, wet, football, better, real, care...\n",
      "25       [f, fly, shabby, #airpower, #gbr, ketv, ethanl...\n",
      "26                  [drying, lincoln, time, kickoff, #gbr]\n",
      "27                                                  [time]\n",
      "28       [hope, nebraska, ohio, state, better, barn, mo...\n",
      "29       [final, thoughts, osu, nebraska, #huskers, pla...\n",
      "                               ...                        \n",
      "13160    [yosoy, kemp, bama, lsu, clemson, georgia, ohi...\n",
      "13161    [huskers, hey, #huskers, happened, see, happen...\n",
      "13162    [like, michigan, look, forward, next, variatio...\n",
      "13163    [laurarutledge, ohiostatefb, auburnfootball, a...\n",
      "13164             [gahhdamn, niggas, even, get, bus, play]\n",
      "13165                    [celebration, lincoln, #buckeyes]\n",
      "13166    [say, heisman, race, heating, post, keep, ener...\n",
      "13167    [jaxfryburger, kirbyownsmullen, true, herbstre...\n",
      "13168    [put, lose, solely, husker, vision, playing, s...\n",
      "13169    [retweeting, honor, #buckeyes, multimillionair...\n",
      "13170    [highlights, ohio, state, blasts, nebraska, li...\n",
      "13171    [mattrudolph, hey, #huskers, happened, see, ha...\n",
      "13172                               [shots, fired, beasts]\n",
      "13173    [buckeye, haters, eat, crow, whooped, nebraska...\n",
      "13174                                         [felt, like]\n",
      "13175    [colton, glad, enjoying, time, amongst, greate...\n",
      "13176                       [forever, red, beatdown, #gbr]\n",
      "13177    [tw, nutz, hangin, congratulations, theohiosta...\n",
      "13178    [sean, callahan, husker, know, name, husker, g...\n",
      "13179    [harmosa, kirkherbstreit, ohiostatefb, huskers...\n",
      "13180                    [nobody, wins, ohio, state, good]\n",
      "13181    [like, week, idk, hate, sports, twitter, mom, ...\n",
      "13182                        [ohio, state, beats, huskers]\n",
      "13183                                    [happy, #gobucks]\n",
      "13184                  [absolutely, rebuilding, year, gbr]\n",
      "13185    [third, time, color, commentator, called, obla...\n",
      "13186    [#ohiostate, #collegefootballplayoff, photo, c...\n",
      "13187    [#husker, volleyball, game, tonight, #gbr, #no...\n",
      "13188                                          [beat, ass]\n",
      "13189           [still, hate, ohio, state, love, nebraska]\n",
      "Name: Text, Length: 13190, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# trying to do a function because just [word for word...] isn't working\n",
    "import ast\n",
    "\n",
    "def removeStopWords(list1):\n",
    "    \"\"\"converts string to an actual list, then removes stop words\"\"\"\n",
    "    actualList = ast.literal_eval(list1)\n",
    "    cleanList = [word for word in actualList if word not in stopWords]\n",
    "    return cleanList\n",
    "\n",
    "\n",
    "tweets['Text'] = tweets['Text'].apply(removeStopWords)\n",
    "\n",
    "# checking that it worked\n",
    "print(tweets['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And removing the words that I used to collect the tweets in the first place (note: I made the string \"ohio state\" that I had originially searched for into two words and removed both): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                            [team, total]\n",
      "1                                           [go, big, red]\n",
      "2                           [brock, osweiler, today, game]\n",
      "3                 [shewrap, win, aldi, kroger, bowl, year]\n",
      "4                                                [let, go]\n",
      "5        [think, tonight, night, adrian, martinez, thro...\n",
      "6        [hours, later, hours, sleep, stop, us, cheerin...\n",
      "7                                            [old, friend]\n",
      "8        [clemson, survives, unc, game, notre, dame, dr...\n",
      "9           [marching, victory, go, link, buy, #toughlove]\n",
      "10                                                  [love]\n",
      "11                [lets, go, bucks, #buckeyenation, #tosu]\n",
      "12       [really, think, fan, unaware, game, go, stomac...\n",
      "13                   [go, jeremy, ruckert, beat, nebraska]\n",
      "14       [tough, especially, ending, clemson, game, sav...\n",
      "15       [hope, nebraska, wins, head, delusional, enoug...\n",
      "16       [old, dominion, played, horrible, st, half, ne...\n",
      "17       [espncfb, hdouglas, treavorscales, picking, oh...\n",
      "18       [neighbors, warned, dinner, crockpot, osu, fla...\n",
      "19       [home, wife, dog, homemade, lasagna, nebraska,...\n",
      "20       [little, cutie, #buckeyenation, baby, buckeye,...\n",
      "21                          [hilarious, fuck, anyone, say]\n",
      "22                       [fight, anyone, says, midwestern]\n",
      "23                                                    [go]\n",
      "24       [wet, field, wet, football, better, real, care...\n",
      "25        [f, fly, shabby, #airpower, ketv, ethanleemedia]\n",
      "26                        [drying, lincoln, time, kickoff]\n",
      "27                                                  [time]\n",
      "28       [hope, nebraska, better, barn, moo, game, moo,...\n",
      "29       [final, thoughts, osu, nebraska, play, incredi...\n",
      "                               ...                        \n",
      "13160    [yosoy, kemp, bama, lsu, clemson, georgia, okl...\n",
      "13161    [hey, happened, see, happens, play, real, team...\n",
      "13162    [like, michigan, look, forward, next, variatio...\n",
      "13163    [laurarutledge, ohiostatefb, auburnfootball, a...\n",
      "13164             [gahhdamn, niggas, even, get, bus, play]\n",
      "13165                               [celebration, lincoln]\n",
      "13166    [say, heisman, race, heating, post, keep, energy]\n",
      "13167    [jaxfryburger, kirbyownsmullen, true, herbstre...\n",
      "13168    [put, lose, solely, vision, playing, songs, go...\n",
      "13169    [retweeting, honor, multimillionaire, scott, f...\n",
      "13170              [highlights, blasts, nebraska, lincoln]\n",
      "13171    [mattrudolph, hey, happened, see, happens, pla...\n",
      "13172                               [shots, fired, beasts]\n",
      "13173    [buckeye, haters, eat, crow, whooped, nebraska...\n",
      "13174                                         [felt, like]\n",
      "13175    [colton, glad, enjoying, time, amongst, greate...\n",
      "13176                             [forever, red, beatdown]\n",
      "13177    [tw, nutz, hangin, congratulations, theohiosta...\n",
      "13178    [sean, callahan, know, name, guy, zero, follow...\n",
      "13179    [harmosa, kirkherbstreit, ohiostatefb, grosse,...\n",
      "13180                                 [nobody, wins, good]\n",
      "13181    [like, week, idk, hate, sports, twitter, mom, ...\n",
      "13182                                              [beats]\n",
      "13183                                              [happy]\n",
      "13184                       [absolutely, rebuilding, year]\n",
      "13185    [third, time, color, commentator, called, obla...\n",
      "13186    [#ohiostate, #collegefootballplayoff, photo, c...\n",
      "13187    [volleyball, game, tonight, #nothingelsetoseeh...\n",
      "13188                                          [beat, ass]\n",
      "13189                        [still, hate, love, nebraska]\n",
      "Name: Text, Length: 13190, dtype: object\n"
     ]
    }
   ],
   "source": [
    "collectionWords = ['husker','huskers','cornhuskers','gbr','ohio', 'state','buckeyes',\n",
    "                    'gobucks','osuvsneb', '#husker','#huskers','#cornhuskers','#gbr',\n",
    "                    '#ohio,''#state','#buckeyes','#gobucks','#osuvsneb']\n",
    "\n",
    "#defining a function to remove collection words\n",
    "def removeCollectionWords(list1):\n",
    "    \"\"\"converts string to an actual list, then removes stop words\"\"\"\n",
    "    cleanList = [word for word in list1 if word not in collectionWords]\n",
    "    return cleanList\n",
    "\n",
    "#applying it\n",
    "tweets['Text'] = tweets['Text'].apply(removeCollectionWords)\n",
    "\n",
    "#checking that it worked\n",
    "print(tweets['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       words  count\n",
      "0   nebraska   1979\n",
      "1       game   1392\n",
      "2       team   1190\n",
      "3       good    932\n",
      "4       like    734\n",
      "5         go    609\n",
      "6        get    584\n",
      "7   football    571\n",
      "8       year    566\n",
      "9    tonight    478\n",
      "10      best    472\n",
      "11      play    463\n",
      "12    fields    455\n",
      "13      time    450\n",
      "14     first    444\n",
      "15      fans    443\n",
      "16      half    435\n",
      "17     right    427\n",
      "18   clemson    421\n",
      "19     going    407\n",
      "20       one    403\n",
      "21       big    376\n",
      "22       let    376\n",
      "23     still    375\n",
      "24    really    371\n"
     ]
    }
   ],
   "source": [
    "# making the tweets into one big list of words\n",
    "allWords = list(itertools.chain(*tweets['Text']))\n",
    "\n",
    "# Create counter\n",
    "countsWords = collections.Counter(allWords)\n",
    "\n",
    "# saving the top 25 words into a dataframe\n",
    "topWords = pd.DataFrame(countsWords.most_common(25),\n",
    "                             columns=['words', 'count'])\n",
    "print(topWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the top 50 words and exporting them so I can graph in Tableau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "topWords.to_csv('Documents/Husker Project/mostCommonWords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the most common Nebraskan (that is, from a user-reported location of Nebraska) words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2245, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nebTweets = tweets[tweets['User Location'] == 'nebraska']\n",
    "nebTweets.head()\n",
    "nebTweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeating the same process to get the most common NE words\n",
    "nebWords = list(itertools.chain(*nebTweets['Text']))\n",
    "nebCountsWords = collections.Counter(nebWords)\n",
    "\n",
    "# and saving to a dataframe\n",
    "nebTopWords = pd.DataFrame(nebCountsWords.most_common(25),\n",
    "                             columns=['words', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the top 50 words and exporting them so I can graph in Tableau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nebTopWords.to_csv('Documents/Husker Project/nebraskaWords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the most common Ohio-an words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process--getting just those tweets from users in Ohio, then putting all of the words together and aggregating word counts!\n",
    "ohioTweets = tweets[tweets['User Location'] == 'ohio']\n",
    "ohioTweets.head()\n",
    "ohioTweets.shape\n",
    "\n",
    "ohioWords = list(itertools.chain(*ohioTweets['Text']))\n",
    "ohioCountsWords = collections.Counter(ohioWords)\n",
    "ohioCountsWords.most_common(150)\n",
    "\n",
    "#and to a dataframe...\n",
    "\n",
    "ohioTopWords = pd.DataFrame(ohioCountsWords.most_common(25),\n",
    "                             columns=['words', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohioTopWords.to_csv('Documents/Husker Project/ohioWords.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
