{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nebraska Cornhuskers vs. Ohio State Buckeyes Game: 9/29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used Tweepy to capture a set of streaming tweets about the Husker game on September 29th. I got the following information related to each Tweet: user name, Tweet ID, the time posted, the user's bio-specified location, Tweet text, the tweet's geo coordinates from which it was sent, whether the Tweet was a Retweet, and whether or not the Tweet was a quote tweet. The code to get Tweets is also available in my Git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Username', 'Tweet ID', 'Time', 'User Location', 'Text',\n",
      "       'Tweet Geo Coordinates', 'Is Retweet', 'Is Quote Tweet'],\n",
      "      dtype='object')\n",
      "(46439, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "tweets = pd.read_csv(\"Documents/Husker Project/gameTweets.csv\")\n",
    "\n",
    "print(tweets.columns)\n",
    "print(tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, I ended up getting over 46,000 Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46439 entries, 0 to 46438\n",
      "Data columns (total 8 columns):\n",
      "Username                 46439 non-null object\n",
      "Tweet ID                 46439 non-null int64\n",
      "Time                     46439 non-null object\n",
      "User Location            33978 non-null object\n",
      "Text                     46439 non-null object\n",
      "Tweet Geo Coordinates    35 non-null object\n",
      "Is Retweet               46439 non-null bool\n",
      "Is Quote Tweet           46439 non-null bool\n",
      "dtypes: bool(2), int64(1), object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using some basic descriptions, I can get who Tweeted the most about the game (or, at least, who Tweeted the most using my keywords):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBJBucksCrew614    87\n",
      "roymdavisll        81\n",
      "Scarletjersey      70\n",
      "Azcroat            65\n",
      "eric_delaluz       65\n",
      "Dukeeeeee_         56\n",
      "BonesHusker        56\n",
      "buckeyeplanet      54\n",
      "BrianDa83878772    51\n",
      "_Heavyy            50\n",
      "Romedawwwg         48\n",
      "dark____master     48\n",
      "Buckeyefanohio7    43\n",
      "JuJu_Da_Gamer      42\n",
      "TNTABDI            42\n",
      "Dan_Hope           42\n",
      "GEWilliams17       40\n",
      "CodySlam           40\n",
      "KJS_football_78    39\n",
      "kelitos_way        39\n",
      "4MEDLEN            39\n",
      "ShalashMuh         37\n",
      "_foodoverlove      37\n",
      "Alaina92871202     37\n",
      "jakedasnake27      36\n",
      "russhein43         36\n",
      "steezmcgavin       34\n",
      "OWHbigred          34\n",
      "dismisstrump       33\n",
      "klovex12           33\n",
      "                   ..\n",
      "AlisonWaiting       1\n",
      "Carraway1980        1\n",
      "BMaendler           1\n",
      "Elijah_127          1\n",
      "VaLuR_              1\n",
      "TarHeelTanMan       1\n",
      "bfarmer1979         1\n",
      "OfficialNathanB     1\n",
      "m_skillman          1\n",
      "K_caballero20       1\n",
      "CNorthzyy           1\n",
      "allboutdough        1\n",
      "SaifJudeh           1\n",
      "ShotgunLund87       1\n",
      "barnett_rc          1\n",
      "LyghtTony           1\n",
      "NotCunit            1\n",
      "jt_parr             1\n",
      "K1NGShawnn          1\n",
      "VickiTreadell       1\n",
      "LordofBones69       1\n",
      "CoachRobPeters      1\n",
      "mattwags4           1\n",
      "Alex_Stepney        1\n",
      "davewillieradio     1\n",
      "RyanWalsh53         1\n",
      "TreyMorris1         1\n",
      "taylerbaby_         1\n",
      "kaylamied           1\n",
      "PasenciaDeleon      1\n",
      "Name: Username, Length: 26185, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Username'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what time most Tweets are posted. This isn't very useful, as it's on a second-by-second basis (and also in UTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-29 00:42:32    22\n",
      "2019-09-29 00:42:09    19\n",
      "2019-09-29 00:39:58    19\n",
      "2019-09-29 01:11:20    18\n",
      "2019-09-29 00:42:37    17\n",
      "2019-09-29 00:42:42    17\n",
      "2019-09-29 00:43:33    17\n",
      "2019-09-29 01:11:31    17\n",
      "2019-09-29 00:43:22    16\n",
      "2019-09-29 00:54:19    16\n",
      "2019-09-29 01:11:11    16\n",
      "2019-09-29 00:12:04    16\n",
      "2019-09-29 00:54:43    16\n",
      "2019-09-29 00:42:49    16\n",
      "2019-09-29 01:13:27    16\n",
      "2019-09-29 01:11:26    16\n",
      "2019-09-29 00:54:20    16\n",
      "2019-09-29 00:42:16    16\n",
      "2019-09-29 00:43:39    16\n",
      "2019-09-29 00:43:08    15\n",
      "2019-09-29 00:45:23    15\n",
      "2019-09-29 01:04:30    15\n",
      "2019-09-29 01:12:32    15\n",
      "2019-09-29 00:42:51    15\n",
      "2019-09-29 01:12:14    15\n",
      "2019-09-29 00:43:04    15\n",
      "2019-09-29 00:43:03    15\n",
      "2019-09-29 01:05:58    15\n",
      "2019-09-29 00:54:39    15\n",
      "2019-09-29 00:41:38    15\n",
      "                       ..\n",
      "2019-09-29 02:09:51     1\n",
      "2019-09-28 23:45:37     1\n",
      "2019-09-29 02:34:07     1\n",
      "2019-09-28 23:39:42     1\n",
      "2019-09-29 02:13:51     1\n",
      "2019-09-28 23:35:39     1\n",
      "2019-09-29 01:43:04     1\n",
      "2019-09-29 02:25:02     1\n",
      "2019-09-29 02:33:38     1\n",
      "2019-09-29 02:40:26     1\n",
      "2019-09-29 02:34:23     1\n",
      "2019-09-29 00:31:59     1\n",
      "2019-09-29 02:34:55     1\n",
      "2019-09-29 02:27:06     1\n",
      "2019-09-29 00:03:52     1\n",
      "2019-09-29 00:07:57     1\n",
      "2019-09-29 02:33:17     1\n",
      "2019-09-29 02:43:55     1\n",
      "2019-09-29 02:35:05     1\n",
      "2019-09-28 23:59:18     1\n",
      "2019-09-29 02:23:31     1\n",
      "2019-09-29 01:33:56     1\n",
      "2019-09-29 01:55:06     1\n",
      "2019-09-28 23:48:38     1\n",
      "2019-09-29 02:29:17     1\n",
      "2019-09-29 01:49:08     1\n",
      "2019-09-29 01:57:32     1\n",
      "2019-09-29 02:08:25     1\n",
      "2019-09-28 23:37:28     1\n",
      "2019-09-29 02:26:29     1\n",
      "Name: Time, Length: 11004, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Time'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for user location! Given how rabid Husker fans can be, I expected more Nebraska locations, but Columbus, OH came out on top. This is a user-generated field (as noted by some of the unusual values down at the bottom, like \"McDonalds,\" \"Lost Continent,\" and a Bible verse), so it'll probably need some cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columbus, OH                    1749\n",
      "Ohio, USA                        909\n",
      "United States                    733\n",
      "Lincoln, NE                      686\n",
      "Omaha, NE                        650\n",
      "Nebraska, USA                    470\n",
      "Ohio                             455\n",
      "Cleveland, OH                    410\n",
      "Columbus, Ohio                   381\n",
      "Nebraska                         310\n",
      "Atlanta, GA                      231\n",
      "Florida, USA                     203\n",
      "Cincinnati, OH                   194\n",
      "Chicago, IL                      189\n",
      "Dallas, TX                       167\n",
      "Los Angeles, CA                  151\n",
      "Texas, USA                       151\n",
      "Lincoln, Nebraska                150\n",
      "Las Vegas, NV                    133\n",
      "USA                              120\n",
      "Houston, TX                      120\n",
      "Charlotte, NC                    112\n",
      "Washington, DC                   111\n",
      "Georgia, USA                     106\n",
      "Austin, TX                       100\n",
      "California, USA                   99\n",
      "Dayton, OH                        99\n",
      "Iowa, USA                         98\n",
      "Kansas City, MO                   98\n",
      "Omaha, Nebraska                   97\n",
      "                                ... \n",
      "KC/CoMo/SoCal                      1\n",
      "United States (The States)         1\n",
      "Ely, IA                            1\n",
      "Ohio/Florida                       1\n",
      "McDonalds                          1\n",
      "Elk River, MN                      1\n",
      "Tampa Florida                      1\n",
      "oc, california                     1\n",
      "Portsmouth, Ohio                   1\n",
      "The good life.                     1\n",
      "OH/Tel'aran'rhiod                  1\n",
      "Valparaiso University              1\n",
      "The Nebraska                       1\n",
      "Flint, Michigan                    1\n",
      "Weighted Blanket, OH               1\n",
      "Where in the world AM I?           1\n",
      "Dublin Ohio                        1\n",
      "Lost Continent                     1\n",
      "Orlando                            1\n",
      "Shakopee, MN, USA                  1\n",
      "Tierra del Fuego                   1\n",
      "Exodus 14:14                       1\n",
      "Freedom, PA                        1\n",
      "Fly Eagles Fly                     1\n",
      "Weatherford, TX                    1\n",
      "Little Switzerland, NC             1\n",
      "Clearfield, UT                     1\n",
      "Mukilteo, Wa                       1\n",
      "Aiken, SC                          1\n",
      "Memphis, TN via Florence, AL       1\n",
      "Name: User Location, Length: 8510, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['User Location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geo coordinates tell where the Tweet was sent from. Unfortunately, very few users have this option turned on, so only a few (35) Tweets showed up. Still, it'll be interesting to see where they are! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN                                                               46404\n",
      "{'type': 'Point', 'coordinates': [-87.85535431, 42.287323]}           3\n",
      "{'type': 'Point', 'coordinates': [-83.01441447, 40.00142341]}         3\n",
      "{'type': 'Point', 'coordinates': [-118.02102287, 33.92233478]}        2\n",
      "{'type': 'Point', 'coordinates': [-96.70594765, 40.82043599]}         2\n",
      "{'type': 'Point', 'coordinates': [-83.00097437, 39.97002125]}         1\n",
      "{'type': 'Point', 'coordinates': [-84.39072, 42.19376]}               1\n",
      "{'type': 'Point', 'coordinates': [-96.70600897, 40.82057983]}         1\n",
      "{'type': 'Point', 'coordinates': [-117.22848, 32.73954]}              1\n",
      "{'type': 'Point', 'coordinates': [-82.95239398, 40.09198467]}         1\n",
      "{'type': 'Point', 'coordinates': [-118.031, 33.9347]}                 1\n",
      "{'type': 'Point', 'coordinates': [-83.09648, 40.06659]}               1\n",
      "{'type': 'Point', 'coordinates': [-118.32929, 34.09996]}              1\n",
      "{'type': 'Point', 'coordinates': [-82.93154, 40.12577]}               1\n",
      "{'type': 'Point', 'coordinates': [-115.16976497, 36.12164075]}        1\n",
      "{'type': 'Point', 'coordinates': [-80.5494, 34.9828]}                 1\n",
      "{'type': 'Point', 'coordinates': [-83.6289, 41.55671]}                1\n",
      "{'type': 'Point', 'coordinates': [-96.7937, 33.2481]}                 1\n",
      "{'type': 'Point', 'coordinates': [-83.05324, 40.03165]}               1\n",
      "{'type': 'Point', 'coordinates': [-81.5229, 40.7953]}                 1\n",
      "{'type': 'Point', 'coordinates': [-83.01046, 40.19932]}               1\n",
      "{'type': 'Point', 'coordinates': [-83.73333787, 41.58233939]}         1\n",
      "{'type': 'Point', 'coordinates': [-74.0064, 40.7142]}                 1\n",
      "{'type': 'Point', 'coordinates': [-86.22539, 39.8525]}                1\n",
      "{'type': 'Point', 'coordinates': [-83.5401, 41.6503]}                 1\n",
      "{'type': 'Point', 'coordinates': [-83.01778078, 39.99482695]}         1\n",
      "{'type': 'Point', 'coordinates': [-83.068, 40.2983]}                  1\n",
      "{'type': 'Point', 'coordinates': [-82.9781698, 40.0630404]}           1\n",
      "{'type': 'Point', 'coordinates': [-94.58214819, 39.097229]}           1\n",
      "{'type': 'Point', 'coordinates': [-84.37829832, 33.92748599]}         1\n",
      "Name: Tweet Geo Coordinates, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Tweet Geo Coordinates'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, lastly, whether or not a Tweet is a quote Tweet or a Retweet. This will be nice to sort on when I just want to analyze unique Tweets, and also for satisfying my curiosity if more people Tweeted or Retweeted game Tweets. It looks like most Tweets weren't Retweets, but they were comparable in volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    24925\n",
      "True     21514\n",
      "Name: Is Retweet, dtype: int64\n",
      "False    40997\n",
      "True      5442\n",
      "Name: Is Quote Tweet, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Is Retweet'].value_counts(dropna=False))\n",
    "print(tweets['Is Quote Tweet'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've got a feel for my data, I'm going to do some cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, cleaning the Tweets. I'm going to make everything lower case, and consider only non-Retweets, loading these into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24925, 8)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonRetweets = tweets.loc[tweets['Is Retweet'] == False].copy() # was getting a SettingWithCopy warning, so making sure that I specified to make a new data set\n",
    "\n",
    "nonRetweets['Text'] = nonRetweets['Text'].str.lower()\n",
    "\n",
    "nonRetweets.shape #and double checking that I get 24925 values..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need to remove punctuation besides hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     buckeyes at cornhuskers  #osuvsneb  here we g...\n",
       "1                        ohio state over    team total\n",
       "2                            go big red  #huskers #gbr\n",
       "3    if he s  good at distracting he could run for ...\n",
       "5    last time ohio state played in lincoln was the...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing urls first\n",
    "\n",
    "h = lambda x: re.sub(r\"http\\S+\", \"\", x)\n",
    "nonRetweets['Text'] = nonRetweets['Text'].apply(h)\n",
    "\n",
    "#then getting rid of other punctuation\n",
    "\n",
    "nonRetweets['Text'] = nonRetweets['Text'].str.replace(\"[^a-zA-Z#]\", \" \") #replacing everything that's not a letter or a hashtag with a space instead\n",
    "nonRetweets['Text'].head() #and checking to see if the data looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, splitting Tweets into individual words so that we can see things like word counts and do sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [buckeyes, at, cornhuskers, #osuvsneb, here, w...\n",
       "1                     [ohio, state, over, team, total]\n",
       "2                       [go, big, red, #huskers, #gbr]\n",
       "3    [if, he, s, good, at, distracting, he, could, ...\n",
       "5    [last, time, ohio, state, played, in, lincoln,...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: x.split() #There's probably a better way to do this, but\n",
    "nonRetweets['Text'] = nonRetweets['Text'].apply(f)\n",
    "#nonRetweets['Text'] = nonRetweets['Text'].split() # there might be a more elegant way to do this, but...\n",
    "nonRetweets['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's it so far for the Tweets themselves. Another problem area? The user-reported locations. We can see from the most common locations that they are commonly in the formats of \"City, Two Letter State,\" \"State, Country,\" \"City, Full State,\" or simply \"State.\" I'm going to use Python's Regular Expression library to get just the Tweets that are in these formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [united, states]\n",
       "1                        [oakland, ca]\n",
       "2    [the, great, state, of, colorado]\n",
       "3                                   []\n",
       "5                                   []\n",
       "Name: User Location, dtype: object"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of punctuation in the location field and then split on whitespace\n",
    "\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].str.replace(\"[^a-zA-Z]\", \" \") #replacing everything that's not a letter with a space instead\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].str.lower() #lower case\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].fillna(\"\") #getting rid of NaN values\n",
    "\n",
    "# using my previous little lambda function. it's probably not good practice to do that...\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].apply(f)\n",
    "nonRetweets['User Location'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2         True\n",
       "3        False\n",
       "5        False\n",
       "6        False\n",
       "7        False\n",
       "8         True\n",
       "9         True\n",
       "11        True\n",
       "12       False\n",
       "14        True\n",
       "15        True\n",
       "16        True\n",
       "17       False\n",
       "18       False\n",
       "19        True\n",
       "21       False\n",
       "22       False\n",
       "23       False\n",
       "25        True\n",
       "26       False\n",
       "28       False\n",
       "29       False\n",
       "30       False\n",
       "31       False\n",
       "33       False\n",
       "34       False\n",
       "35        True\n",
       "36       False\n",
       "         ...  \n",
       "46354     True\n",
       "46358     True\n",
       "46359     True\n",
       "46360    False\n",
       "46361     True\n",
       "46365    False\n",
       "46366    False\n",
       "46368    False\n",
       "46371     True\n",
       "46373    False\n",
       "46382     True\n",
       "46389    False\n",
       "46391    False\n",
       "46395     True\n",
       "46396     True\n",
       "46400     True\n",
       "46404     True\n",
       "46406    False\n",
       "46408     True\n",
       "46410    False\n",
       "46418    False\n",
       "46422     True\n",
       "46423     True\n",
       "46424     True\n",
       "46425    False\n",
       "46428    False\n",
       "46431    False\n",
       "46433    False\n",
       "46434    False\n",
       "46435    False\n",
       "Name: User Location, Length: 24925, dtype: bool"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of states\n",
    "states = [\"alabama\",\"alaska\",\"arizona\",\"arkansas\",\"california\",\"colorado\",\n",
    "  \"connecticut\",\"delaware\",\"florida\",\"georgia\",\"hawaii\",\"idaho\",\"illinois\",\n",
    "  \"indiana\",\"iowa\",\"kansas\",\"kentucky\",\"louisiana\",\"maine\",\"maryland\",\n",
    "  \"massachusetts\",\"michigan\",\"minnesota\",\"mississippi\",\"missouri\",\"montana\",\n",
    "  \"nebraska\",\"nevada\",\"new hampshire\",\"new jersey\",\"new mexico\",\"new york\",\n",
    "  \"north carolina\",\"north dakota\",\"ohio\",\"oklahoma\",\"oregon\",\"pennsylvania\",\n",
    "  \"rhode island\",\"south carolina\",\"south dakota\",\"tennessee\",\"texas\",\"utah\",\n",
    "  \"vermont\",\"virginia\",\"washington\",\"west virginia\",\"wisconsin\",\"wyoming\"]\n",
    "\n",
    "# list of abbreviations\n",
    "\n",
    "stateAbbreviations =  [\"al\", \"ak\", \"az\", \"ar\", \"ca\", \"co\", \"ct\", \"dc\", \"de\", \"fl\", \"ga\", \n",
    "          \"hi\", \"id\", \"il\", \"in\", \"ia\", \"ks\", \"ky\", \"la\", \"me\", \"md\", \n",
    "          \"ma\", \"mi\", \"mn\", \"ms\", \"mo\", \"mt\", \"ne\", \"nv\", \"nh\", \"nj\", \n",
    "          \"nm\", \"ny\", \"nc\", \"nd\", \"oh\", \"ok\", \"or\", \"pa\", \"ri\", \"sc\", \n",
    "          \"sd\", \"tn\", \"tx\", \"ut\", \"vt\", \"va\", \"wa\", \"wv\", \"wi\", \"wy\"]\n",
    "\n",
    "# dictionary for transitioning between abbreviations and states\n",
    "\n",
    "abbrevToState = {\n",
    "        'ak': 'alaska',\n",
    "        'al': 'alabama',\n",
    "        'ar': 'arkansas',\n",
    "        'as': 'american Samoa',\n",
    "        'az': 'arizona',\n",
    "        'ca': 'california',\n",
    "        'co': 'colorado',\n",
    "        'ct': 'connecticut',\n",
    "        'dc': 'district of columbia',\n",
    "        'de': 'delaware',\n",
    "        'fl': 'florida',\n",
    "        'ga': 'georgia',\n",
    "        'hi': 'hawaii',\n",
    "        'ia': 'iowa',\n",
    "        'id': 'idaho',\n",
    "        'il': 'illinois',\n",
    "        'in': 'indiana',\n",
    "        'ks': 'kansas',\n",
    "        'ky': 'kentucky',\n",
    "        'la': 'louisiana',\n",
    "        'ma': 'massachusetts',\n",
    "        'md': 'maryland',\n",
    "        'me': 'maine',\n",
    "        'mi': 'michigan',\n",
    "        'mn': 'minnesota',\n",
    "        'mo': 'missouri',\n",
    "        'ms': 'mississippi',\n",
    "        'mt': 'montana',\n",
    "        'nc': 'north carolina',\n",
    "        'nd': 'north dakota',\n",
    "        'ne': 'nebraska',\n",
    "        'nh': 'new hampshire',\n",
    "        'nj': 'new jersey',\n",
    "        'nm': 'new mexico',\n",
    "        'nv': 'nevada',\n",
    "        'ny': 'new york',\n",
    "        'oh': 'ohio',\n",
    "        'ok': 'oklahoma',\n",
    "        'or': 'oregon',\n",
    "        'pa': 'pennsylvania',\n",
    "        'ri': 'rhode island',\n",
    "        'sc': 'south carolina',\n",
    "        'sd': 'south dakota',\n",
    "        'tn': 'tennessee',\n",
    "        'tx': 'texas',\n",
    "        'ut': 'utah',\n",
    "        'va': 'virginia',\n",
    "        'vt': 'vermont',\n",
    "        'wa': 'washington',\n",
    "        'wi': 'wisconsin',\n",
    "        'wv': 'west virginia',\n",
    "        'wy': 'wyoming'\n",
    "}\n",
    "\n",
    "\n",
    "# checking if anything in the user location matches a state abbreviation or a full state name\n",
    "def stateChecker(list1, list2, list3, dict1):\n",
    "    if any(item in list1 for item in list2): # first checking the first list against the second\n",
    "        if len(set(list1)&set(list2)) == 1: # making sure there aren't multiple states listed\n",
    "            list1 = list(set(list1)&set(list2)) # getting only the value that matches (the abbreviation)\n",
    "            list1 = list1[0] # and getting only the value itself\n",
    "            list1 = dict1[list1] #then, setting the value of the user location to the corresponding state\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif any (item in list1 for item in list3):\n",
    "        if len(set(list1)&set(list3)) == 1:\n",
    "            list1 = list(set(list1)&set(list3)) # getting only the value that matches (the state name)\n",
    "            list1 = list1[0] # and getting only the value itself\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# then going through the user location field and applying it to each one\n",
    "\n",
    "nonRetweets['User Location'].apply(stateChecker, args = (stateAbbreviations,states,abbrevToState))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tweet Geo Coordinates</th>\n",
       "      <th>Is Retweet</th>\n",
       "      <th>Is Quote Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WinnersStrictly</td>\n",
       "      <td>1178090727709872128</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>[oakland, ca]</td>\n",
       "      <td>[ohio, state, over, team, total]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LucasLee45</td>\n",
       "      <td>1178090728418725889</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>[the, great, state, of, colorado]</td>\n",
       "      <td>[go, big, red, #huskers, #gbr]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PhilBergmanTV</td>\n",
       "      <td>1178090742197166080</td>\n",
       "      <td>2019-09-28 23:34:55</td>\n",
       "      <td>[omaha, ne]</td>\n",
       "      <td>[brock, osweiler, at, today, s, #huskers, game]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prodby2LoKi</td>\n",
       "      <td>1178090747209359361</td>\n",
       "      <td>2019-09-28 23:34:56</td>\n",
       "      <td>[norfside, huntsville, al]</td>\n",
       "      <td>[shewrap, ohio, state, when, they, win, the, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DownWithDamon</td>\n",
       "      <td>1178090757892255744</td>\n",
       "      <td>2019-09-28 23:34:59</td>\n",
       "      <td>[cleveland, oh]</td>\n",
       "      <td>[let, s, go, buckeyes]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Username             Tweet ID                 Time  \\\n",
       "1   WinnersStrictly  1178090727709872128  2019-09-28 23:34:52   \n",
       "2        LucasLee45  1178090728418725889  2019-09-28 23:34:52   \n",
       "8     PhilBergmanTV  1178090742197166080  2019-09-28 23:34:55   \n",
       "9       Prodby2LoKi  1178090747209359361  2019-09-28 23:34:56   \n",
       "11    DownWithDamon  1178090757892255744  2019-09-28 23:34:59   \n",
       "\n",
       "                        User Location  \\\n",
       "1                       [oakland, ca]   \n",
       "2   [the, great, state, of, colorado]   \n",
       "8                         [omaha, ne]   \n",
       "9          [norfside, huntsville, al]   \n",
       "11                    [cleveland, oh]   \n",
       "\n",
       "                                                 Text Tweet Geo Coordinates  \\\n",
       "1                    [ohio, state, over, team, total]                   NaN   \n",
       "2                      [go, big, red, #huskers, #gbr]                   NaN   \n",
       "8     [brock, osweiler, at, today, s, #huskers, game]                   NaN   \n",
       "9   [shewrap, ohio, state, when, they, win, the, a...                   NaN   \n",
       "11                             [let, s, go, buckeyes]                   NaN   \n",
       "\n",
       "    Is Retweet  Is Quote Tweet  \n",
       "1        False           False  \n",
       "2        False           False  \n",
       "8        False           False  \n",
       "9        False           False  \n",
       "11       False           False  "
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then, getting my final tweet set of tweets only that have an identifiable state location\n",
    "finalTweetSet = nonRetweets.loc[nonRetweets['User Location'].apply(stateChecker, args = (stateAbbreviations,states,abbrevToState))].copy()\n",
    "\n",
    "finalTweetSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     california\n",
       "2       colorado\n",
       "8       nebraska\n",
       "9        alabama\n",
       "11          ohio\n",
       "Name: User Location, dtype: object"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then renaming the user locations to simply the state of origin\n",
    "\n",
    "def stateGetter(list1, list2, list3, dict1):\n",
    "    if any(item in list1 for item in list2): # first checking the first list against the second\n",
    "        list1 = list(set(list1)&set(list2)) # getting only the value that matches (the abbreviation)\n",
    "        list1 = list1[0] # and getting only the value itself\n",
    "        list1 = dict1[list1] #then, setting the value of the user location to the corresponding state\n",
    "        return list1\n",
    "    elif any (item in list1 for item in list3):\n",
    "        list1 = list(set(list1)&set(list3)) # getting only the value that matches (the state name)\n",
    "        list1 = list1[0] # and getting only the value itself\n",
    "        return list1\n",
    "\n",
    "\n",
    "# renaming\n",
    "finalTweetSet['User Location'] = finalTweetSet['User Location'].apply(stateGetter, args = (stateAbbreviations,states,abbrevToState,))\n",
    "\n",
    "#checking\n",
    "finalTweetSet['User Location'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I need to convert the time stamp from UTC to Central Time, which helps coordinate Tweets with game events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2019-09-28 18:34:52\n",
       "2    2019-09-28 18:34:52\n",
       "8    2019-09-28 18:34:55\n",
       "9    2019-09-28 18:34:56\n",
       "11   2019-09-28 18:34:59\n",
       "Name: Time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting it as a time object\n",
    "g = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "finalTweetSet['Time'] = finalTweetSet['Time'].apply(g)\n",
    "\n",
    "# then subtracting five hours, so it's in Central Time, not UTC\n",
    "\n",
    "finalTweetSet['Time'] = finalTweetSet['Time']-timedelta(hours = 5)\n",
    "finalTweetSet['Time'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And checking my beautiful data set, and sending it to a .csv so I can do analysis in Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTweetSet.head(15)\n",
    "\n",
    "finalTweetSet.to_csv('Documents/Husker Project/cleanedGameTweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I'm going to do a lot of visualization in Tableau, here are some preliminary findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top states that were Tweeting about the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top words used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a bigger assignment: which words most correctly predict a user-specified location of Nebraska? How about of Ohio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another bigger assignment: sentiment analysis for Tweets from Nebraska vs Ohio at the end of the game.\n",
    "\n",
    "Ooh! And sentiment analysis of Tweets from Nebraska before the game vs. after, so you can watch our hope die!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyses to do in Tableau:  Pie chart of Tweets vs Retweets\n",
    "\n",
    "                            Map colored by # of Tweets\n",
    "                            \n",
    "                            Tweet volume as the game went along, also marked with events (TDs, bad calls, breaks)\n",
    "                            \n",
    "                            Sentiment analysis at end of game for Tweets from Ohio vs from Nebraska\n",
    "                            \n",
    "                            Keywords from various time buckets (2 minutes of game time?)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
