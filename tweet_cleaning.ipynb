{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nebraska Cornhuskers vs. Ohio State Buckeyes Game: 9/29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used Tweepy to capture a set of streaming tweets about the Husker game on September 28th, using the keywords 'husker,''huskers,''cornhuskers,''gbr,''ohio state,''buckeyes,''gobucks,''OSUvsNEB.' I got the following information related to each Tweet: user name, Tweet ID, the time posted, the user's bio-specified location, Tweet text, the tweet's geo coordinates from which it was sent, whether the Tweet was a Retweet, and whether or not the Tweet was a quote tweet. The code to get Tweets is also available in my Git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Username', 'Tweet ID', 'Time', 'User Location', 'Text',\n",
      "       'Tweet Geo Coordinates', 'Is Retweet', 'Is Quote Tweet'],\n",
      "      dtype='object')\n",
      "(46439, 8)\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob\n",
    "\n",
    "# getting the data \n",
    "tweets = pd.read_csv(\"Documents/Husker Project/gameTweets.csv\")\n",
    "\n",
    "#checking the info about the tweets\n",
    "\n",
    "print(tweets.columns)\n",
    "print(tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, I ended up getting over 46,000 Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46439 entries, 0 to 46438\n",
      "Data columns (total 8 columns):\n",
      "Username                 46439 non-null object\n",
      "Tweet ID                 46439 non-null int64\n",
      "Time                     46439 non-null object\n",
      "User Location            33978 non-null object\n",
      "Text                     46439 non-null object\n",
      "Tweet Geo Coordinates    35 non-null object\n",
      "Is Retweet               46439 non-null bool\n",
      "Is Quote Tweet           46439 non-null bool\n",
      "dtypes: bool(2), int64(1), object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# a bit more information about the data I collected\n",
    "\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using some basic descriptions, I can get who Tweeted the most about the game (or, at least, who Tweeted the most using my keywords):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBJBucksCrew614    87\n",
      "roymdavisll        81\n",
      "Scarletjersey      70\n",
      "Azcroat            65\n",
      "eric_delaluz       65\n",
      "Dukeeeeee_         56\n",
      "BonesHusker        56\n",
      "buckeyeplanet      54\n",
      "BrianDa83878772    51\n",
      "_Heavyy            50\n",
      "Romedawwwg         48\n",
      "dark____master     48\n",
      "Buckeyefanohio7    43\n",
      "JuJu_Da_Gamer      42\n",
      "Dan_Hope           42\n",
      "TNTABDI            42\n",
      "CodySlam           40\n",
      "GEWilliams17       40\n",
      "kelitos_way        39\n",
      "KJS_football_78    39\n",
      "4MEDLEN            39\n",
      "Alaina92871202     37\n",
      "_foodoverlove      37\n",
      "ShalashMuh         37\n",
      "jakedasnake27      36\n",
      "russhein43         36\n",
      "OWHbigred          34\n",
      "steezmcgavin       34\n",
      "klovex12           33\n",
      "dismisstrump       33\n",
      "                   ..\n",
      "Reeed210000         1\n",
      "charles90542553     1\n",
      "sampasser           1\n",
      "J_Labbs             1\n",
      "sarahdactyl93       1\n",
      "BigDickerEnergy     1\n",
      "Nathan_Wear         1\n",
      "gd04051973          1\n",
      "jason__hernan       1\n",
      "THEchrisHOKE        1\n",
      "WVUMajor9           1\n",
      "joshstevenson23     1\n",
      "aijahogan           1\n",
      "Maximizealot        1\n",
      "Live4Gr8ness        1\n",
      "cyrus_hudspeth      1\n",
      "bogden86            1\n",
      "TyvTyy              1\n",
      "noahscroggins7      1\n",
      "NathanNgottier      1\n",
      "RedBluePurple_      1\n",
      "queenassassian      1\n",
      "StultzBrian         1\n",
      "bvelaski            1\n",
      "TylerGlassburn      1\n",
      "mgrubb11_mike       1\n",
      "ShaunFischer        1\n",
      "lebronsouffle       1\n",
      "BrownsBucksFan      1\n",
      "sdav08              1\n",
      "Name: Username, Length: 26185, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Username'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what time most Tweets are posted. This isn't very useful, as it's on a second-by-second basis (and also in UTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-29 00:42:32    22\n",
      "2019-09-29 00:42:09    19\n",
      "2019-09-29 00:39:58    19\n",
      "2019-09-29 01:11:20    18\n",
      "2019-09-29 00:43:33    17\n",
      "2019-09-29 00:42:42    17\n",
      "2019-09-29 00:42:37    17\n",
      "2019-09-29 01:11:31    17\n",
      "2019-09-29 01:11:26    16\n",
      "2019-09-29 00:42:16    16\n",
      "2019-09-29 01:11:11    16\n",
      "2019-09-29 00:54:19    16\n",
      "2019-09-29 01:13:27    16\n",
      "2019-09-29 00:42:49    16\n",
      "2019-09-29 00:54:20    16\n",
      "2019-09-29 00:43:22    16\n",
      "2019-09-29 00:12:04    16\n",
      "2019-09-29 00:54:43    16\n",
      "2019-09-29 00:43:39    16\n",
      "2019-09-29 00:43:04    15\n",
      "2019-09-29 00:54:26    15\n",
      "2019-09-29 01:12:14    15\n",
      "2019-09-29 00:42:53    15\n",
      "2019-09-29 01:05:58    15\n",
      "2019-09-29 01:12:32    15\n",
      "2019-09-29 00:43:08    15\n",
      "2019-09-29 00:42:51    15\n",
      "2019-09-29 00:43:03    15\n",
      "2019-09-29 00:45:23    15\n",
      "2019-09-29 00:41:38    15\n",
      "                       ..\n",
      "2019-09-29 01:54:14     1\n",
      "2019-09-28 23:59:13     1\n",
      "2019-09-29 02:26:42     1\n",
      "2019-09-29 00:32:35     1\n",
      "2019-09-29 00:15:15     1\n",
      "2019-09-29 02:10:37     1\n",
      "2019-09-29 02:10:49     1\n",
      "2019-09-29 00:36:09     1\n",
      "2019-09-29 02:29:12     1\n",
      "2019-09-28 23:42:10     1\n",
      "2019-09-29 00:16:38     1\n",
      "2019-09-29 01:53:32     1\n",
      "2019-09-29 00:43:55     1\n",
      "2019-09-28 23:53:43     1\n",
      "2019-09-29 00:33:14     1\n",
      "2019-09-29 02:20:16     1\n",
      "2019-09-29 02:24:46     1\n",
      "2019-09-29 02:21:30     1\n",
      "2019-09-29 00:04:57     1\n",
      "2019-09-29 01:46:18     1\n",
      "2019-09-29 01:59:21     1\n",
      "2019-09-28 23:46:23     1\n",
      "2019-09-29 00:45:08     1\n",
      "2019-09-29 02:34:46     1\n",
      "2019-09-29 00:13:46     1\n",
      "2019-09-28 23:38:30     1\n",
      "2019-09-29 00:48:12     1\n",
      "2019-09-29 00:16:16     1\n",
      "2019-09-28 23:40:13     1\n",
      "2019-09-29 01:23:53     1\n",
      "Name: Time, Length: 11004, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Time'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for user location! Given how rabid Husker fans can be, I expected more Nebraska locations, but Columbus, OH came out on top. This is a user-generated field (as noted by some of the unusual values down at the bottom, like \"McDonalds,\" \"Lost Continent,\" and a Bible verse), so it'll probably need some cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columbus, OH                      1749\n",
      "Ohio, USA                          909\n",
      "United States                      733\n",
      "Lincoln, NE                        686\n",
      "Omaha, NE                          650\n",
      "Nebraska, USA                      470\n",
      "Ohio                               455\n",
      "Cleveland, OH                      410\n",
      "Columbus, Ohio                     381\n",
      "Nebraska                           310\n",
      "Atlanta, GA                        231\n",
      "Florida, USA                       203\n",
      "Cincinnati, OH                     194\n",
      "Chicago, IL                        189\n",
      "Dallas, TX                         167\n",
      "Texas, USA                         151\n",
      "Los Angeles, CA                    151\n",
      "Lincoln, Nebraska                  150\n",
      "Las Vegas, NV                      133\n",
      "Houston, TX                        120\n",
      "USA                                120\n",
      "Charlotte, NC                      112\n",
      "Washington, DC                     111\n",
      "Georgia, USA                       106\n",
      "Austin, TX                         100\n",
      "Dayton, OH                          99\n",
      "California, USA                     99\n",
      "Kansas City, MO                     98\n",
      "Iowa, USA                           98\n",
      "Michigan, USA                       97\n",
      "                                  ... \n",
      "Ohio Northern University             1\n",
      " Virgina, USA                        1\n",
      "Honeycomb Hideout                    1\n",
      "The middle of corn country           1\n",
      "Mike Scott’s Hive                    1\n",
      "Woodland, CA.                        1\n",
      "Oxford, AL                           1\n",
      "Garland, Texas                       1\n",
      "NEBRASKA - Honestly, its cool        1\n",
      "Cleveland // Athens                  1\n",
      "Newton Falls by way of Mpls          1\n",
      "Christ have mercy                    1\n",
      "At a baseball game or vacation       1\n",
      "Rubicon, WI                          1\n",
      "The road to success...               1\n",
      "Rolling Meadows, IL                  1\n",
      "Decatur, Al                          1\n",
      "Sioux Falls                          1\n",
      "Louisiana⚜️                          1\n",
      "Fowler, Indiana                      1\n",
      "The Ohio River Basin                 1\n",
      "West Jefferson, NC                   1\n",
      "Manchester/Ann Arbor, MI             1\n",
      "New York milly rockin                1\n",
      "Decatur, Illinois                    1\n",
      "Tokyo                                1\n",
      "uniontown, ohio                      1\n",
      "215/610                              1\n",
      "Albany, Ga.                          1\n",
      "late cretaceous                      1\n",
      "Name: User Location, Length: 8510, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['User Location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geo coordinates tell where the Tweet was sent from. Unfortunately, very few users have this option turned on, so only a few (35) Tweets showed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN                                                               46404\n",
      "{'type': 'Point', 'coordinates': [-83.01441447, 40.00142341]}         3\n",
      "{'type': 'Point', 'coordinates': [-87.85535431, 42.287323]}           3\n",
      "{'type': 'Point', 'coordinates': [-96.70594765, 40.82043599]}         2\n",
      "{'type': 'Point', 'coordinates': [-118.02102287, 33.92233478]}        2\n",
      "{'type': 'Point', 'coordinates': [-118.32929, 34.09996]}              1\n",
      "{'type': 'Point', 'coordinates': [-82.9781698, 40.0630404]}           1\n",
      "{'type': 'Point', 'coordinates': [-96.70600897, 40.82057983]}         1\n",
      "{'type': 'Point', 'coordinates': [-83.5401, 41.6503]}                 1\n",
      "{'type': 'Point', 'coordinates': [-115.16976497, 36.12164075]}        1\n",
      "{'type': 'Point', 'coordinates': [-86.22539, 39.8525]}                1\n",
      "{'type': 'Point', 'coordinates': [-82.93154, 40.12577]}               1\n",
      "{'type': 'Point', 'coordinates': [-83.6289, 41.55671]}                1\n",
      "{'type': 'Point', 'coordinates': [-94.58214819, 39.097229]}           1\n",
      "{'type': 'Point', 'coordinates': [-83.068, 40.2983]}                  1\n",
      "{'type': 'Point', 'coordinates': [-80.5494, 34.9828]}                 1\n",
      "{'type': 'Point', 'coordinates': [-96.7937, 33.2481]}                 1\n",
      "{'type': 'Point', 'coordinates': [-83.05324, 40.03165]}               1\n",
      "{'type': 'Point', 'coordinates': [-84.39072, 42.19376]}               1\n",
      "{'type': 'Point', 'coordinates': [-83.09648, 40.06659]}               1\n",
      "{'type': 'Point', 'coordinates': [-83.01778078, 39.99482695]}         1\n",
      "{'type': 'Point', 'coordinates': [-83.73333787, 41.58233939]}         1\n",
      "{'type': 'Point', 'coordinates': [-81.5229, 40.7953]}                 1\n",
      "{'type': 'Point', 'coordinates': [-83.01046, 40.19932]}               1\n",
      "{'type': 'Point', 'coordinates': [-84.37829832, 33.92748599]}         1\n",
      "{'type': 'Point', 'coordinates': [-117.22848, 32.73954]}              1\n",
      "{'type': 'Point', 'coordinates': [-83.00097437, 39.97002125]}         1\n",
      "{'type': 'Point', 'coordinates': [-82.95239398, 40.09198467]}         1\n",
      "{'type': 'Point', 'coordinates': [-74.0064, 40.7142]}                 1\n",
      "{'type': 'Point', 'coordinates': [-118.031, 33.9347]}                 1\n",
      "Name: Tweet Geo Coordinates, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Tweet Geo Coordinates'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, lastly, whether or not a Tweet is a quote Tweet or a Retweet. This could be nice to sort on when I just want to analyze unique Tweets, and also for satisfying my curiosity if more people Tweeted or Retweeted game Tweets. It looks like most Tweets weren't Retweets, but they were comparable in volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    24925\n",
      "True     21514\n",
      "Name: Is Retweet, dtype: int64\n",
      "False    40997\n",
      "True      5442\n",
      "Name: Is Quote Tweet, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Is Retweet'].value_counts(dropna=False))\n",
    "print(tweets['Is Quote Tweet'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've got a feel for my data, I'm going to do some cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, cleaning the Tweets. I'm going to make everything lower case, and consider only non-Retweets, loading these into a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24925, 8)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonRetweets = tweets.loc[tweets['Is Retweet'] == False].copy() # was getting a SettingWithCopy warning, so making sure that I specified to make a new data set\n",
    "\n",
    "#making everything lower case\n",
    "\n",
    "nonRetweets['Text'] = nonRetweets['Text'].str.lower()\n",
    "\n",
    "nonRetweets.shape #and double checking that I get 24925 values..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need to remove punctuation besides hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     buckeyes at cornhuskers  #osuvsneb  here we g...\n",
       "1                        ohio state over    team total\n",
       "2                            go big red  #huskers #gbr\n",
       "3    if he s  good at distracting he could run for ...\n",
       "5    last time ohio state played in lincoln was the...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing urls first\n",
    "\n",
    "h = lambda x: re.sub(r\"http\\S+\", \"\", x)\n",
    "nonRetweets['Text'] = nonRetweets['Text'].apply(h)\n",
    "\n",
    "#then getting rid of other punctuation\n",
    "\n",
    "nonRetweets['Text'] = nonRetweets['Text'].str.replace(\"[^a-zA-Z#]\", \" \") #replacing everything that's not a letter or a hashtag with a space instead\n",
    "nonRetweets['Text'].head() #and checking to see if the data looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to graph sentiment analysis for the Tweets as well, and since this is done using the WordBlob package on strings and not lists of words, I'm going to add a new column and calculate the sentiment score for each individual Tweet now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Making a text blob for each tweet, following a great tutorial from earthdatascience.org\n",
    "\n",
    "sentiment_objects = [TextBlob(tweet) for tweet in nonRetweets['Text']]\n",
    "\n",
    "#then making a list of polarity values\n",
    "sentiment_values = [tweet.sentiment.polarity for tweet in sentiment_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tweet Geo Coordinates</th>\n",
       "      <th>Is Retweet</th>\n",
       "      <th>Is Quote Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NANxox2_WOKE</td>\n",
       "      <td>1178090726854418433</td>\n",
       "      <td>2019-09-28 23:34:51</td>\n",
       "      <td>United States</td>\n",
       "      <td>buckeyes at cornhuskers  #osuvsneb  here we g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WinnersStrictly</td>\n",
       "      <td>1178090727709872128</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>ohio state over    team total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LucasLee45</td>\n",
       "      <td>1178090728418725889</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>The GREAT State of Colorado.</td>\n",
       "      <td>go big red  #huskers #gbr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kaine7061</td>\n",
       "      <td>1178090728674791424</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if he s  good at distracting he could run for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dpm917</td>\n",
       "      <td>1178090731753349122</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>last time ohio state played in lincoln was the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aderetzi_</td>\n",
       "      <td>1178090733003083777</td>\n",
       "      <td>2019-09-28 23:34:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i m cryin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MikeSpector01</td>\n",
       "      <td>1178090743547727872</td>\n",
       "      <td>2019-09-28 23:34:55</td>\n",
       "      <td>New Jersey, USA</td>\n",
       "      <td>when vegas casino heads say they need nebraska...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PhilBergmanTV</td>\n",
       "      <td>1178090742197166080</td>\n",
       "      <td>2019-09-28 23:34:55</td>\n",
       "      <td>Omaha, NE</td>\n",
       "      <td>brock osweiler at today s #huskers game</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prodby2LoKi</td>\n",
       "      <td>1178090747209359361</td>\n",
       "      <td>2019-09-28 23:34:56</td>\n",
       "      <td>Norfside, Huntsville, AL</td>\n",
       "      <td>shewrap ohio state when they win the aldi kro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DownWithDamon</td>\n",
       "      <td>1178090757892255744</td>\n",
       "      <td>2019-09-28 23:34:59</td>\n",
       "      <td>Cleveland, OH</td>\n",
       "      <td>let s go buckeyes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Username             Tweet ID                 Time  \\\n",
       "0      NANxox2_WOKE  1178090726854418433  2019-09-28 23:34:51   \n",
       "1   WinnersStrictly  1178090727709872128  2019-09-28 23:34:52   \n",
       "2        LucasLee45  1178090728418725889  2019-09-28 23:34:52   \n",
       "3         Kaine7061  1178090728674791424  2019-09-28 23:34:52   \n",
       "5            dpm917  1178090731753349122  2019-09-28 23:34:52   \n",
       "6         aderetzi_  1178090733003083777  2019-09-28 23:34:53   \n",
       "7     MikeSpector01  1178090743547727872  2019-09-28 23:34:55   \n",
       "8     PhilBergmanTV  1178090742197166080  2019-09-28 23:34:55   \n",
       "9       Prodby2LoKi  1178090747209359361  2019-09-28 23:34:56   \n",
       "11    DownWithDamon  1178090757892255744  2019-09-28 23:34:59   \n",
       "\n",
       "                   User Location  \\\n",
       "0                  United States   \n",
       "1                    Oakland, CA   \n",
       "2   The GREAT State of Colorado.   \n",
       "3                            NaN   \n",
       "5                            NaN   \n",
       "6                            NaN   \n",
       "7                New Jersey, USA   \n",
       "8                      Omaha, NE   \n",
       "9       Norfside, Huntsville, AL   \n",
       "11                 Cleveland, OH   \n",
       "\n",
       "                                                 Text Tweet Geo Coordinates  \\\n",
       "0    buckeyes at cornhuskers  #osuvsneb  here we g...                   NaN   \n",
       "1                       ohio state over    team total                   NaN   \n",
       "2                           go big red  #huskers #gbr                   NaN   \n",
       "3   if he s  good at distracting he could run for ...                   NaN   \n",
       "5   last time ohio state played in lincoln was the...                   NaN   \n",
       "6                                      i m cryin                        NaN   \n",
       "7   when vegas casino heads say they need nebraska...                   NaN   \n",
       "8            brock osweiler at today s #huskers game                    NaN   \n",
       "9    shewrap ohio state when they win the aldi kro...                   NaN   \n",
       "11                                 let s go buckeyes                    NaN   \n",
       "\n",
       "    Is Retweet  Is Quote Tweet  Sentiment  \n",
       "0        False           False       0.00  \n",
       "1        False           False       0.00  \n",
       "2        False           False       0.00  \n",
       "3        False            True       0.70  \n",
       "5        False           False      -0.06  \n",
       "6        False            True       0.00  \n",
       "7        False           False       0.00  \n",
       "8        False           False      -0.40  \n",
       "9        False           False       0.80  \n",
       "11       False           False       0.00  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and attaching this list as a new column in the dataframe\n",
    "\n",
    "nonRetweets['Sentiment'] = sentiment_values\n",
    "\n",
    "nonRetweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, splitting Tweets into individual words so that we can see things like word counts and do sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [buckeyes, at, cornhuskers, #osuvsneb, here, w...\n",
       "1                     [ohio, state, over, team, total]\n",
       "2                       [go, big, red, #huskers, #gbr]\n",
       "3    [if, he, s, good, at, distracting, he, could, ...\n",
       "5    [last, time, ohio, state, played, in, lincoln,...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: x.split() #making a lambda function rather than defining something big for one action\n",
    "nonRetweets['Text'] = nonRetweets['Text'].apply(f)\n",
    "\n",
    "#checking to be sure it did what I wanted\n",
    "\n",
    "nonRetweets['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's it so far for the Tweets themselves. Another problem area? The user-reported locations. We can see from the most common locations that they are commonly in the formats of \"City, Two Letter State,\" \"State, Country,\" \"City, Full State,\" or simply \"State.\" I'm going to split the location field into whitespace-separated words, and then check these against a list of state names and state abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [united, states]\n",
       "1                        [oakland, ca]\n",
       "2    [the, great, state, of, colorado]\n",
       "3                                   []\n",
       "5                                   []\n",
       "Name: User Location, dtype: object"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the 'User Location' field nicer to analyze\n",
    "\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].str.replace(\"[^a-zA-Z]\", \" \") #replacing everything that's not a letter with a space instead\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].str.lower() #lower case\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].fillna(\"\") #getting rid of NaN values\n",
    "\n",
    "# using my previous little lambda function to split\n",
    "\n",
    "nonRetweets['User Location'] = nonRetweets['User Location'].apply(f)\n",
    "nonRetweets['User Location'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2         True\n",
       "3        False\n",
       "5        False\n",
       "6        False\n",
       "7        False\n",
       "8         True\n",
       "9         True\n",
       "11        True\n",
       "12       False\n",
       "14        True\n",
       "15        True\n",
       "16        True\n",
       "17       False\n",
       "18       False\n",
       "19        True\n",
       "21       False\n",
       "22       False\n",
       "23       False\n",
       "25        True\n",
       "26       False\n",
       "28       False\n",
       "29       False\n",
       "30       False\n",
       "31       False\n",
       "33       False\n",
       "34       False\n",
       "35        True\n",
       "36       False\n",
       "         ...  \n",
       "46354     True\n",
       "46358     True\n",
       "46359     True\n",
       "46360    False\n",
       "46361     True\n",
       "46365    False\n",
       "46366    False\n",
       "46368    False\n",
       "46371     True\n",
       "46373    False\n",
       "46382     True\n",
       "46389    False\n",
       "46391    False\n",
       "46395     True\n",
       "46396     True\n",
       "46400     True\n",
       "46404     True\n",
       "46406    False\n",
       "46408     True\n",
       "46410    False\n",
       "46418    False\n",
       "46422     True\n",
       "46423     True\n",
       "46424     True\n",
       "46425    False\n",
       "46428    False\n",
       "46431    False\n",
       "46433    False\n",
       "46434    False\n",
       "46435    False\n",
       "Name: User Location, Length: 24925, dtype: bool"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of states\n",
    "states = [\"alabama\",\"alaska\",\"arizona\",\"arkansas\",\"california\",\"colorado\",\n",
    "  \"connecticut\",\"delaware\",\"florida\",\"georgia\",\"hawaii\",\"idaho\",\"illinois\",\n",
    "  \"indiana\",\"iowa\",\"kansas\",\"kentucky\",\"louisiana\",\"maine\",\"maryland\",\n",
    "  \"massachusetts\",\"michigan\",\"minnesota\",\"mississippi\",\"missouri\",\"montana\",\n",
    "  \"nebraska\",\"nevada\",\"new hampshire\",\"new jersey\",\"new mexico\",\"new york\",\n",
    "  \"north carolina\",\"north dakota\",\"ohio\",\"oklahoma\",\"oregon\",\"pennsylvania\",\n",
    "  \"rhode island\",\"south carolina\",\"south dakota\",\"tennessee\",\"texas\",\"utah\",\n",
    "  \"vermont\",\"virginia\",\"washington\",\"west virginia\",\"wisconsin\",\"wyoming\"]\n",
    "\n",
    "# list of abbreviations\n",
    "\n",
    "stateAbbreviations =  [\"al\", \"ak\", \"az\", \"ar\", \"ca\", \"co\", \"ct\", \"dc\", \"de\", \"fl\", \"ga\", \n",
    "          \"hi\", \"id\", \"il\", \"in\", \"ia\", \"ks\", \"ky\", \"la\", \"me\", \"md\", \n",
    "          \"ma\", \"mi\", \"mn\", \"ms\", \"mo\", \"mt\", \"ne\", \"nv\", \"nh\", \"nj\", \n",
    "          \"nm\", \"ny\", \"nc\", \"nd\", \"oh\", \"ok\", \"or\", \"pa\", \"ri\", \"sc\", \n",
    "          \"sd\", \"tn\", \"tx\", \"ut\", \"vt\", \"va\", \"wa\", \"wv\", \"wi\", \"wy\"]\n",
    "\n",
    "# dictionary for transitioning between abbreviations and states\n",
    "\n",
    "abbrevToState = {\n",
    "        'ak': 'alaska',\n",
    "        'al': 'alabama',\n",
    "        'ar': 'arkansas',\n",
    "        'as': 'american Samoa',\n",
    "        'az': 'arizona',\n",
    "        'ca': 'california',\n",
    "        'co': 'colorado',\n",
    "        'ct': 'connecticut',\n",
    "        'dc': 'district of columbia',\n",
    "        'de': 'delaware',\n",
    "        'fl': 'florida',\n",
    "        'ga': 'georgia',\n",
    "        'hi': 'hawaii',\n",
    "        'ia': 'iowa',\n",
    "        'id': 'idaho',\n",
    "        'il': 'illinois',\n",
    "        'in': 'indiana',\n",
    "        'ks': 'kansas',\n",
    "        'ky': 'kentucky',\n",
    "        'la': 'louisiana',\n",
    "        'ma': 'massachusetts',\n",
    "        'md': 'maryland',\n",
    "        'me': 'maine',\n",
    "        'mi': 'michigan',\n",
    "        'mn': 'minnesota',\n",
    "        'mo': 'missouri',\n",
    "        'ms': 'mississippi',\n",
    "        'mt': 'montana',\n",
    "        'nc': 'north carolina',\n",
    "        'nd': 'north dakota',\n",
    "        'ne': 'nebraska',\n",
    "        'nh': 'new hampshire',\n",
    "        'nj': 'new jersey',\n",
    "        'nm': 'new mexico',\n",
    "        'nv': 'nevada',\n",
    "        'ny': 'new york',\n",
    "        'oh': 'ohio',\n",
    "        'ok': 'oklahoma',\n",
    "        'or': 'oregon',\n",
    "        'pa': 'pennsylvania',\n",
    "        'ri': 'rhode island',\n",
    "        'sc': 'south carolina',\n",
    "        'sd': 'south dakota',\n",
    "        'tn': 'tennessee',\n",
    "        'tx': 'texas',\n",
    "        'ut': 'utah',\n",
    "        'va': 'virginia',\n",
    "        'vt': 'vermont',\n",
    "        'wa': 'washington',\n",
    "        'wi': 'wisconsin',\n",
    "        'wv': 'west virginia',\n",
    "        'wy': 'wyoming'\n",
    "}\n",
    "\n",
    "\n",
    "# checking if anything in the user location matches a state abbreviation or a full state name\n",
    "def stateChecker(list1, list2, list3, dict1):\n",
    "    if any(item in list1 for item in list2): # first checking the first list against the second\n",
    "        if len(set(list1)&set(list2)) == 1: # making sure there aren't multiple states listed\n",
    "            list1 = list(set(list1)&set(list2)) # getting only the value that matches (the abbreviation)\n",
    "            list1 = list1[0] # and getting only the value itself\n",
    "            list1 = dict1[list1] #then, setting the value of the user location to the corresponding state\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif any (item in list1 for item in list3):\n",
    "        if len(set(list1)&set(list3)) == 1:\n",
    "            list1 = list(set(list1)&set(list3)) # getting only the value that matches (the state name)\n",
    "            list1 = list1[0] # and getting only the value itself\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# then going through the user location field and applying it to each one\n",
    "\n",
    "nonRetweets['User Location'].apply(stateChecker, args = (stateAbbreviations,states,abbrevToState))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tweet Geo Coordinates</th>\n",
       "      <th>Is Retweet</th>\n",
       "      <th>Is Quote Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WinnersStrictly</td>\n",
       "      <td>1178090727709872128</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>[oakland, ca]</td>\n",
       "      <td>[ohio, state, over, team, total]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LucasLee45</td>\n",
       "      <td>1178090728418725889</td>\n",
       "      <td>2019-09-28 23:34:52</td>\n",
       "      <td>[the, great, state, of, colorado]</td>\n",
       "      <td>[go, big, red, #huskers, #gbr]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PhilBergmanTV</td>\n",
       "      <td>1178090742197166080</td>\n",
       "      <td>2019-09-28 23:34:55</td>\n",
       "      <td>[omaha, ne]</td>\n",
       "      <td>[brock, osweiler, at, today, s, #huskers, game]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prodby2LoKi</td>\n",
       "      <td>1178090747209359361</td>\n",
       "      <td>2019-09-28 23:34:56</td>\n",
       "      <td>[norfside, huntsville, al]</td>\n",
       "      <td>[shewrap, ohio, state, when, they, win, the, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DownWithDamon</td>\n",
       "      <td>1178090757892255744</td>\n",
       "      <td>2019-09-28 23:34:59</td>\n",
       "      <td>[cleveland, oh]</td>\n",
       "      <td>[let, s, go, buckeyes]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Username             Tweet ID                 Time  \\\n",
       "1   WinnersStrictly  1178090727709872128  2019-09-28 23:34:52   \n",
       "2        LucasLee45  1178090728418725889  2019-09-28 23:34:52   \n",
       "8     PhilBergmanTV  1178090742197166080  2019-09-28 23:34:55   \n",
       "9       Prodby2LoKi  1178090747209359361  2019-09-28 23:34:56   \n",
       "11    DownWithDamon  1178090757892255744  2019-09-28 23:34:59   \n",
       "\n",
       "                        User Location  \\\n",
       "1                       [oakland, ca]   \n",
       "2   [the, great, state, of, colorado]   \n",
       "8                         [omaha, ne]   \n",
       "9          [norfside, huntsville, al]   \n",
       "11                    [cleveland, oh]   \n",
       "\n",
       "                                                 Text Tweet Geo Coordinates  \\\n",
       "1                    [ohio, state, over, team, total]                   NaN   \n",
       "2                      [go, big, red, #huskers, #gbr]                   NaN   \n",
       "8     [brock, osweiler, at, today, s, #huskers, game]                   NaN   \n",
       "9   [shewrap, ohio, state, when, they, win, the, a...                   NaN   \n",
       "11                             [let, s, go, buckeyes]                   NaN   \n",
       "\n",
       "    Is Retweet  Is Quote Tweet  Sentiment  \n",
       "1        False           False        0.0  \n",
       "2        False           False        0.0  \n",
       "8        False           False       -0.4  \n",
       "9        False           False        0.8  \n",
       "11       False           False        0.0  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then, getting my final tweet set of tweets only that have an identifiable state location\n",
    "finalTweetSet = nonRetweets.loc[nonRetweets['User Location'].apply(stateChecker, args = (stateAbbreviations,states,abbrevToState))].copy()\n",
    "\n",
    "finalTweetSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then renaming the user locations to simply the state of origin\n",
    "\n",
    "def stateGetter(list1, list2, list3, dict1):\n",
    "    if any(item in list1 for item in list2): # first checking the first list against the second\n",
    "        list1 = list(set(list1)&set(list2)) # getting only the value that matches (the abbreviation)\n",
    "        list1 = list1[0] # and getting only the value itself\n",
    "        list1 = dict1[list1] #then, setting the value of the user location to the corresponding state\n",
    "        return list1\n",
    "    elif any (item in list1 for item in list3):\n",
    "        list1 = list(set(list1)&set(list3)) # getting only the value that matches (the state name)\n",
    "        list1 = list1[0] # and getting only the value itself\n",
    "        return list1\n",
    "\n",
    "finalTweetSet['User Location'] = finalTweetSet['User Location'].apply(stateGetter, args = (stateAbbreviations,states,abbrevToState,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     California\n",
       "2       Colorado\n",
       "8       Nebraska\n",
       "9        Alabama\n",
       "11          Ohio\n",
       "Name: User Location, dtype: object"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#capitalizing state names to make visualization in Tableau easier later\n",
    "\n",
    "finalTweetSet['User Location'] = finalTweetSet['User Location'].str.title()\n",
    "\n",
    "#checking that it worked...\n",
    "finalTweetSet['User Location'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I need to convert the time stamp from UTC to Central Time (the game was played in Nebraska), which helps coordinate Tweets with game events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2019-09-28 18:34:52\n",
       "2    2019-09-28 18:34:52\n",
       "8    2019-09-28 18:34:55\n",
       "9    2019-09-28 18:34:56\n",
       "11   2019-09-28 18:34:59\n",
       "Name: Time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting it as a time object\n",
    "g = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "finalTweetSet['Time'] = finalTweetSet['Time'].apply(g)\n",
    "\n",
    "# then subtracting five hours, so it's in Central Time, not UTC\n",
    "\n",
    "finalTweetSet['Time'] = finalTweetSet['Time']-timedelta(hours = 5)\n",
    "finalTweetSet['Time'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And checking my beautiful data set, and sending it to a .csv so I can do analysis in Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tweet Geo Coordinates</th>\n",
       "      <th>Is Retweet</th>\n",
       "      <th>Is Quote Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WinnersStrictly</td>\n",
       "      <td>1178090727709872128</td>\n",
       "      <td>2019-09-28 18:34:52</td>\n",
       "      <td>California</td>\n",
       "      <td>[ohio, state, over, team, total]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LucasLee45</td>\n",
       "      <td>1178090728418725889</td>\n",
       "      <td>2019-09-28 18:34:52</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>[go, big, red, #huskers, #gbr]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PhilBergmanTV</td>\n",
       "      <td>1178090742197166080</td>\n",
       "      <td>2019-09-28 18:34:55</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>[brock, osweiler, at, today, s, #huskers, game]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Prodby2LoKi</td>\n",
       "      <td>1178090747209359361</td>\n",
       "      <td>2019-09-28 18:34:56</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>[shewrap, ohio, state, when, they, win, the, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DownWithDamon</td>\n",
       "      <td>1178090757892255744</td>\n",
       "      <td>2019-09-28 18:34:59</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>[let, s, go, buckeyes]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eyeformation</td>\n",
       "      <td>1178090766155046914</td>\n",
       "      <td>2019-09-28 18:35:01</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>[i, think, tonight, is, the, night, that, adri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nutMEG_4</td>\n",
       "      <td>1178090765932781569</td>\n",
       "      <td>2019-09-28 18:35:01</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>[hours, later, off, hours, of, sleep, but, it,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Broncos_Reddit</td>\n",
       "      <td>1178090768940048385</td>\n",
       "      <td>2019-09-28 18:35:01</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>[old, friend]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jbc_sports_ops</td>\n",
       "      <td>1178090772127768579</td>\n",
       "      <td>2019-09-28 18:35:02</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>[clemson, survives, unc, but, what, a, game, n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>intltrends</td>\n",
       "      <td>1178090776225570816</td>\n",
       "      <td>2019-09-28 18:35:03</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>[no, ohio, state, marching, to, victory, go, b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LSueSzabo</td>\n",
       "      <td>1178090789047537665</td>\n",
       "      <td>2019-09-28 18:35:06</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>[love, my, buckeyes]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>uKeepWhatuKiII</td>\n",
       "      <td>1178090799042482176</td>\n",
       "      <td>2019-09-28 18:35:09</td>\n",
       "      <td>California</td>\n",
       "      <td>[lets, go, bucks, #gobucks, #buckeyenation, #t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>meghanitNASTY2</td>\n",
       "      <td>1178090814888648704</td>\n",
       "      <td>2019-09-28 18:35:12</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>[do, you, really, think, that, as, a, husker, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ToddBrennan</td>\n",
       "      <td>1178090817635917824</td>\n",
       "      <td>2019-09-28 18:35:13</td>\n",
       "      <td>New York</td>\n",
       "      <td>[go, jeremy, ruckert, and, ohio, state, beat, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WeekendSportsUp</td>\n",
       "      <td>1178090826611736577</td>\n",
       "      <td>2019-09-28 18:35:15</td>\n",
       "      <td>California</td>\n",
       "      <td>[it, was, tough, especially, with, the, ending...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.223148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Username             Tweet ID                Time User Location  \\\n",
       "1   WinnersStrictly  1178090727709872128 2019-09-28 18:34:52    California   \n",
       "2        LucasLee45  1178090728418725889 2019-09-28 18:34:52      Colorado   \n",
       "8     PhilBergmanTV  1178090742197166080 2019-09-28 18:34:55      Nebraska   \n",
       "9       Prodby2LoKi  1178090747209359361 2019-09-28 18:34:56       Alabama   \n",
       "11    DownWithDamon  1178090757892255744 2019-09-28 18:34:59          Ohio   \n",
       "14     eyeformation  1178090766155046914 2019-09-28 18:35:01      Nebraska   \n",
       "15         nutMEG_4  1178090765932781569 2019-09-28 18:35:01      Nebraska   \n",
       "16   Broncos_Reddit  1178090768940048385 2019-09-28 18:35:01      Colorado   \n",
       "19   jbc_sports_ops  1178090772127768579 2019-09-28 18:35:02       Georgia   \n",
       "25       intltrends  1178090776225570816 2019-09-28 18:35:03       Indiana   \n",
       "35        LSueSzabo  1178090789047537665 2019-09-28 18:35:06          Ohio   \n",
       "39   uKeepWhatuKiII  1178090799042482176 2019-09-28 18:35:09    California   \n",
       "43   meghanitNASTY2  1178090814888648704 2019-09-28 18:35:12        Kansas   \n",
       "44      ToddBrennan  1178090817635917824 2019-09-28 18:35:13      New York   \n",
       "49  WeekendSportsUp  1178090826611736577 2019-09-28 18:35:15    California   \n",
       "\n",
       "                                                 Text Tweet Geo Coordinates  \\\n",
       "1                    [ohio, state, over, team, total]                   NaN   \n",
       "2                      [go, big, red, #huskers, #gbr]                   NaN   \n",
       "8     [brock, osweiler, at, today, s, #huskers, game]                   NaN   \n",
       "9   [shewrap, ohio, state, when, they, win, the, a...                   NaN   \n",
       "11                             [let, s, go, buckeyes]                   NaN   \n",
       "14  [i, think, tonight, is, the, night, that, adri...                   NaN   \n",
       "15  [hours, later, off, hours, of, sleep, but, it,...                   NaN   \n",
       "16                                      [old, friend]                   NaN   \n",
       "19  [clemson, survives, unc, but, what, a, game, n...                   NaN   \n",
       "25  [no, ohio, state, marching, to, victory, go, b...                   NaN   \n",
       "35                               [love, my, buckeyes]                   NaN   \n",
       "39  [lets, go, bucks, #gobucks, #buckeyenation, #t...                   NaN   \n",
       "43  [do, you, really, think, that, as, a, husker, ...                   NaN   \n",
       "44  [go, jeremy, ruckert, and, ohio, state, beat, ...                   NaN   \n",
       "49  [it, was, tough, especially, with, the, ending...                   NaN   \n",
       "\n",
       "    Is Retweet  Is Quote Tweet  Sentiment  \n",
       "1        False           False   0.000000  \n",
       "2        False           False   0.000000  \n",
       "8        False           False  -0.400000  \n",
       "9        False           False   0.800000  \n",
       "11       False           False   0.000000  \n",
       "14       False           False   0.000000  \n",
       "15       False           False   0.400000  \n",
       "16       False            True   0.100000  \n",
       "19       False           False   0.311111  \n",
       "25       False           False   0.000000  \n",
       "35       False            True   0.500000  \n",
       "39       False           False   0.000000  \n",
       "43       False           False  -0.066667  \n",
       "44       False           False   0.000000  \n",
       "49       False           False  -0.223148  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTweetSet.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTweetSet.to_csv('Documents/Husker Project/cleanedGameTweets2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
